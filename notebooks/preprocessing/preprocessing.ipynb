{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing\n",
    "\n",
    "### This notebook walks through the process of preparing a single region  & zone of imagrey and polygon labels to be used in a deep learning model\n",
    "\n",
    "The high level steps are as follows:\n",
    "1. Create tile cells over the extent of the zone\n",
    "2. Subset these tiles into training and validation sets\n",
    "3. Clip the aerial imagery to the tiles\n",
    "4. Clip the polygon labels to the corresponding aerial imgagery tiles\n",
    "5. Bun the polygons into rasterize mask tiles\n",
    "6. Save the final image tiles and mask tiles in relative directories\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rio_tiler import main as rt_main\n",
    "import mercantile\n",
    "from rasterio.transform import from_bounds\n",
    "from shapely.geometry import Polygon\n",
    "from shapely.ops import cascaded_union\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%aimport src.utilities\n",
    "%aimport src.visualization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modules to reload:\n",
      "src.utilities src.visualization\n",
      "\n",
      "Modules to skip:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%aimport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set the file paths for the first selected COG and labels:\n",
    "region = 'mon'\n",
    "zone = '207cc7'\n",
    "train_directory = 'train_tier_1'\n",
    "\n",
    "# load geojson for labels\n",
    "label_gdf, geotif =proc.import_data(zone = zone, region = region, train_tier = train_directory)\n",
    "\n",
    "# geojson = f'../../data/raw/{train_directory}/{region}/{zone}-labels/{zone}.geojson'\n",
    "# geotif = f'../../data/raw/{train_directory}/{region}/{zone}/{zone}.tif'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #make the directories to store processed/output data\n",
    "img_path, mask_path = proc.make_processed_directories(zone = zone, region = region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 609
    },
    "colab_type": "code",
    "id": "-6b56_XJn2NT",
    "outputId": "e6f410b8-4f7b-4edd-f949-64814639c9fa"
   },
   "outputs": [],
   "source": [
    "#visualize the label polygons\n",
    "label_gdf.plot(figsize=(10,10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creat training and validation subsets of the geometry\n",
    "\n",
    "We need the polygons and the geotif imagery to be clipped into small tiles in order to be processes and eventually fed into a a CNN. To begin with we need to take the following steps:\n",
    "\n",
    "1. Using supermercado tile burn method to create square polygon \"cells\" representing all the slippy map tiles at a specified zoom level that overlap the labeled polygons. \n",
    "2. Then we seperate these cells into training and validation sets. \n",
    "\n",
    "\n",
    "### Methodology and strategy for splitting: \n",
    "Originally I was splitting the training and validation set based on the bounds. I would seperate the extent into 20/80 slplit. I had a hunch that this type of split could lead to variance senstivity in my model. If intead the validation cells are sprinkled throughout the entire region, it will more randomly train the model and prevent sensitivity to geographic interdependencies.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the tile size and zoom level for the burned tiles\n",
    "zoom_level = 19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use the supermercado burn tiles method to create a new geojson with slippy tiles \n",
    "proc.burn_tiles(region = region, zone = zone, zoom_level= zoom_level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tiles_df = proc.load_tile_geojson(region = region, zone = zone, visualize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tiles_gdf = proc.train_validation_split(tiles_df,valid_set_size=.2, visualize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the tiles over the polygons\n",
    "vis.visualize_burned_cells(tiles_gdf, label_gdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create xyz column \n",
    "tiles_gdf = proc.reformat_xyz(tiles_gdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load/crop COGtiff  to the area of a sinlge burned tile\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define tile size. here we will use 256x256 pixel \n",
    "tile_size = 256\n",
    "\n",
    "#Choose a random tile's id:\n",
    "idx = 30\n",
    "\n",
    "#clip the tile\n",
    "tile, mask = rt_main.tile(geotif, *tiles_gdf.iloc[idx]['xyz'], tilesize=tile_size)\n",
    "\n",
    "#display the clipped COGtif\n",
    "plt.imshow(np.moveaxis(tile,0,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crop the label polygons to the area of the same tile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the geometries from the geodataframe\n",
    "all_polys_series = label_gdf.geometry\n",
    "# preemptively fix and merge any invalid or overlapping geoms that would otherwise throw errors during the rasterize step. \n",
    "all_polys_series = proc.cleanup_invalid_geoms(all_polys_series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the same tile polygon as our tile image above\n",
    "\n",
    "tile_poly = proc.get_specific_tile(idx = idx, tiles_gdf=tiles_gdf)\n",
    "tile_poly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the Affine Transformation Matrix\n",
    "tfm = proc.tfm(tile_poly, 256)\n",
    "tfm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cropped_polys = proc.clip_singletile_polys(idx = idx, tiles_gdf = tiles_gdf, \n",
    "                                           all_polys_series= all_polys_series, tile_size = tile_size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Use solaris to create a pixel mask\n",
    "\n",
    "We'll create our corresponding 3-channel RGB mask by passing the cropped polygons to solaris' df_to_px_mask function. \n",
    "\n",
    "- 1st (Red) channel represent building footprints,\n",
    "- 2nd (Green) channel represent building boundaries (visually looks yellow on the RGB mask display because the pixels overlap red and green+red=yellow),\n",
    "-  3rd (Blue) channel represent close contact points between adjacent buildings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# burn a footprint/boundary/contact 3-channel mask with solaris: https://solaris.readthedocs.io/en/latest/tutorials/notebooks/api_masks_tutorial.html\n",
    "\n",
    "fbc_mask = proc.burn_mask(cropped_polys_gdf=cropped_polys, tfm = tfm, tile_size=256, channels=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualize the new mask next to the COGtiff tile\n",
    "fig, (ax1, ax2) = plt.subplots(1,2,figsize=(10, 5))\n",
    "ax1.imshow(np.moveaxis(tile,0,2))\n",
    "ax2.imshow(fbc_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualize the new mask overlaying COGtiff tile\n",
    "fig, ax = plt.subplots( figsize=(10,10))\n",
    "ax.imshow(np.moveaxis(tile,0,2))\n",
    "ax.imshow(fbc_mask, alpha = .3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualize the 3 bands (footpring, boundary, contact)\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(1,3,figsize=(10, 5))\n",
    "ax1.imshow(fbc_mask[:,:,0])\n",
    "ax2.imshow(fbc_mask[:,:,1])\n",
    "ax3.imshow(fbc_mask[:,:,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# idx = 14\n",
    "# tile_poly = proc.get_specific_tile(idx = idx, tiles_gdf=tiles_gdf)\n",
    "# # tiles_gdf.iloc[idx]['dataset']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proc.save_tile_img(geotif,xyz=tiles_gdf.iloc[idx]['xyz'], dataset=tiles_gdf.iloc[idx]['dataset'], tile_size=256,\n",
    "                   zone=zone, region=region, save_path=img_path, display=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "proc.save_tile_mask(all_polys_series, tile_poly, tiles_gdf.iloc[idx]['xyz'], dataset=tiles_gdf.iloc[idx]['dataset'],\n",
    "                    tile_size=256, zone = zone, region= region, \n",
    "                    save_path=mask_path,channels=1, display=True )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clip all of the aerial imagery cells, clip all of the polygons, and rasterize all of the labels \n",
    "\n",
    "Combine the above process into functions in order to batch process the entire regeion. This will generate the full training and validation sets of Slippy tile cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check the # of tiles that should result from each set:\n",
    "tiles_gdf[tiles_gdf['dataset'] == 'training'].shape, tiles_gdf[tiles_gdf['dataset'] == 'validation'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#total number of iterations to expect for the batch processing:\n",
    "len(tiles_gdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#batch process the entire COG and save all of the tiles\n",
    "proc.batch_save_tile_img(tiles_gdf= tiles_gdf, tif= geotif, tile_size=256, zone=zone, \n",
    "                         region= region, save_path= img_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#batch process the entire set of polygon labels and save all of the tiles\n",
    "\n",
    "proc.batch_save_tile_mask(tiles_gdf= tiles_gdf, label_poly_series= all_polys_series, tile_size= 256, region= region,\n",
    "                         zone= zone, save_path= mask_path, channels=1, display=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check that the labels and COG cells saved correctly and that the label masks are burned:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use glob to put all of the file names into a dataframe for easy access \n",
    "df_filepaths = proc.make_filepath_df(region = region,zone = zone, zoom_level = 19)\n",
    "df_filepaths.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis.visualize_saved_tiles(5,10, df_filepaths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NOTE: the above region's total cells make up ~53 mb of data: 49 from the COG tiles and 3 from the masks. This makes\n",
    "# it seem way more possible to just have everything on my local machine. \n",
    "\n",
    "#That being said, can mount drive and save all of the tiles to google drive if run the following:\n",
    "\n",
    "# # compress and download\n",
    "# !tar -czf znz001trn.tar.gz data\n",
    "\n",
    "# #save to drive\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "BS_dataprep.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Solaris",
   "language": "python",
   "name": "solaris"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
